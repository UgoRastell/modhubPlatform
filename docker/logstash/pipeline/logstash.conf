input {
  # Collecter les logs via TCP
  tcp {
    port => 5000
    codec => json_lines
    tags => ["docker"]
  }

  # Collecter les logs via UDP (Syslog)
  udp {
    port => 5000
    codec => json_lines
    tags => ["docker"]
  }
  
  # Collecter les logs via fichiers
  file {
    path => "/var/log/modhub/**/*.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    tags => ["file"]
  }
}

filter {
  # Parse JSON logs
  if "docker" in [tags] {
    json {
      source => "message"
    }
  }
  
  # Ajouter un timestamp si absent
  if ![timestamp] and [time] {
    mutate {
      add_field => { "timestamp" => "%{time}" }
    }
  }
  
  # Conversion du timestamp si présent
  if [timestamp] {
    date {
      match => [ "timestamp", "ISO8601", "yyyy-MM-dd HH:mm:ss,SSS", "yyyy-MM-dd HH:mm:ss.SSS" ]
      target => "@timestamp"
      remove_field => [ "timestamp", "time" ]
    }
  }
  
  # Extraire des informations des messages .NET
  if [message] =~ /^\[.*\]/ {
    grok {
      match => { "message" => "\[%{LOGLEVEL:level}\]%{GREEDYDATA:message}" }
    }
  }
  
  # Classifier les logs par niveau de sévérité
  if [level] {
    mutate {
      lowercase => [ "level" ]
    }
  }
  
  # Extraire les informations de traçage pour les requêtes HTTP
  if [message] =~ /HTTP/ {
    grok {
      match => { "message" => "(?:%{IPORHOST:clientip}|-) %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] \"(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})\" %{NUMBER:response} (?:%{NUMBER:bytes}|-) %{QS:referrer} %{QS:agent}" }
    }
  }
}

output {
  # Sortie vers Elasticsearch
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logstash-%{+YYYY.MM.dd}"
    document_type => "log"
  }
  
  # Sortie vers console pour débogage (commentée en production)
  # stdout { codec => rubydebug }
}
